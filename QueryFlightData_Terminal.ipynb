{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Query for Terminal Area IFF Flight Record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set spark environments\n",
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = '/home/ypang6/anaconda3/lib/python3.7/site-packages/pyspark'\n",
    "os.environ[\"PYTHONPATH\"] = '/home/ypang6/anaconda3/bin/python3.7'\n",
    "os.environ['PYSPARK_PYTHON'] = '/home/ypang6/anaconda3/bin/python3.7'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/home/ypang6/anaconda3/bin/python3.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Terminal_Area_Flight_Data_Query\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom schema of the data\n",
    "### References to IFF_2.13_Specs_Sherlock.doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myschema = StructType([\n",
    "    StructField(\"recType\", ShortType(), True),  #1  //track point record type number\n",
    "    StructField(\"recTime\", StringType(), True),  #2  //seconds since midnigght 1/1/70 UTC\n",
    "    StructField(\"fltKey\", LongType(), True),  #3  //flight key\n",
    "    StructField(\"bcnCode\", IntegerType(), True),  #4  //digit range from 0 to 7\n",
    "    StructField(\"cid\", IntegerType(), True),  #5  //computer flight id\n",
    "    StructField(\"Source\", StringType(), True),  #6  //source of the record \n",
    "    StructField(\"msgType\", StringType(), True),  #7\n",
    "    StructField(\"acId\", StringType(), True),  #8  //call sign\n",
    "    StructField(\"recTypeCat\", IntegerType(), True),  #9\n",
    "    StructField(\"lat\", DoubleType(), True),  #10\n",
    "    StructField(\"lon\", DoubleType(), True),  #11 \n",
    "    StructField(\"alt\", DoubleType(), True),  #12  //in 100s of feet\n",
    "    StructField(\"significance\", ShortType(), True),  #13 //digit range from 1 to 10\n",
    "    StructField(\"latAcc\", DoubleType(), True),  #14\n",
    "    StructField(\"lonAcc\", DoubleType(), True),  #15\n",
    "    StructField(\"altAcc\", DoubleType(), True),  #16\n",
    "    StructField(\"groundSpeed\", IntegerType(), True),  #17 //in knots\n",
    "    StructField(\"course\", DoubleType(), True),  #18  //in degrees from true north\n",
    "    StructField(\"rateOfClimb\", DoubleType(), True),  #19  //in feet per minute\n",
    "    StructField(\"altQualifier\", StringType(), True),  #20  //Altitude qualifier (the “B4 character”)\n",
    "    StructField(\"altIndicator\", StringType(), True),  #21  //Altitude indicator (the “C4 character”)\n",
    "    StructField(\"trackPtStatus\", StringType(), True),  #22  //Track point status (e.g., ‘C’ for coast)\n",
    "    StructField(\"leaderDir\", IntegerType(), True),  #23  //int 0-8 representing the direction of the leader line\n",
    "    StructField(\"scratchPad\", StringType(), True),  #24\n",
    "    StructField(\"msawInhibitInd\", ShortType(), True),  #25 // MSAW Inhibit Indicator (0=not inhibited, 1=inhibited)\n",
    "    StructField(\"assignedAltString\", StringType(), True),  #26 \n",
    "    StructField(\"controllingFac\", StringType(), True),  #27\n",
    "    StructField(\"controllingSec\", StringType(), True),  #28\n",
    "    StructField(\"receivingFac\", StringType(), True),  #29\n",
    "    StructField(\"receivingSec\", StringType(), True),  #30\n",
    "    StructField(\"activeContr\", IntegerType(), True),  #31  // the active control number\n",
    "    StructField(\"primaryContr\", IntegerType(), True),  #32  //The primary(previous, controlling, or possible next)controller number\n",
    "    StructField(\"kybrdSubset\", StringType(), True),  #33  //identifies a subset of controller keyboards\n",
    "    StructField(\"kybrdSymbol\", StringType(), True),  #34  //identifies a keyboard within the keyboard subsets\n",
    "    StructField(\"adsCode\", IntegerType(), True),  #35  //arrival departure status code\n",
    "    StructField(\"opsType\", StringType(), True),  #36  //Operations type (O/E/A/D/I/U)from ARTS and ARTS 3A data\n",
    "    StructField(\"airportCode\", StringType(), True),  #37 \n",
    "    StructField(\"trackNumber\", IntegerType(), True),  #38\n",
    "    StructField(\"tptReturnType\", StringType(), True),  #39\n",
    "    StructField(\"modeSCode\", StringType(), True)  #40\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 20190801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_path = glob.glob(\"/media/ypang6/paralab/Research/data/ATL/IFF_ATL+ASDEX_{}*.csv\".format(date))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(file_path, header=False, sep=\",\", schema=myschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "start_date = 20190801\n",
    "end_date = 20190831\n",
    "for date in range(start_date, end_date+1):\n",
    "    #print(date)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count row numbers of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1876430"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- recType: short (nullable = true)\n",
      " |-- recTime: string (nullable = true)\n",
      " |-- fltKey: long (nullable = true)\n",
      " |-- bcnCode: integer (nullable = true)\n",
      " |-- cid: integer (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- msgType: string (nullable = true)\n",
      " |-- acId: string (nullable = true)\n",
      " |-- recTypeCat: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- alt: double (nullable = true)\n",
      " |-- significance: short (nullable = true)\n",
      " |-- latAcc: double (nullable = true)\n",
      " |-- lonAcc: double (nullable = true)\n",
      " |-- altAcc: double (nullable = true)\n",
      " |-- groundSpeed: integer (nullable = true)\n",
      " |-- course: double (nullable = true)\n",
      " |-- rateOfClimb: double (nullable = true)\n",
      " |-- altQualifier: string (nullable = true)\n",
      " |-- altIndicator: string (nullable = true)\n",
      " |-- trackPtStatus: string (nullable = true)\n",
      " |-- leaderDir: integer (nullable = true)\n",
      " |-- scratchPad: string (nullable = true)\n",
      " |-- msawInhibitInd: short (nullable = true)\n",
      " |-- assignedAltString: string (nullable = true)\n",
      " |-- controllingFac: string (nullable = true)\n",
      " |-- controllingSec: string (nullable = true)\n",
      " |-- receivingFac: string (nullable = true)\n",
      " |-- receivingSec: string (nullable = true)\n",
      " |-- activeContr: integer (nullable = true)\n",
      " |-- primaryContr: integer (nullable = true)\n",
      " |-- kybrdSubset: string (nullable = true)\n",
      " |-- kybrdSymbol: string (nullable = true)\n",
      " |-- adsCode: integer (nullable = true)\n",
      " |-- opsType: string (nullable = true)\n",
      " |-- airportCode: string (nullable = true)\n",
      " |-- trackNumber: integer (nullable = true)\n",
      " |-- tptReturnType: string (nullable = true)\n",
      " |-- modeSCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['recType', 'recTime', 'acId', 'lat', 'lon', 'alt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(*cols).filter(df['recType']==3).withColumn(\"recTime\", df['recTime'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = 1567346400  # 2PM \n",
    "FAF_9L = (33.63465, -84.54984166666667)  # waypoint NIVII (FAF of KATL runway 9L)\n",
    "FAF_9R = (33.63172777777777, -84.54940555555555)  # waypoint BURNY (FAF of KATL runway 9R)\n",
    "IF_9R = (33.631397222222226, -84.71883611111112)  # waypoint GGUYY (IF of KATL runway 9R)\n",
    "IAF_9L = (33.63394722222222, -84.86316388888888) # waypoint RYENN (IAF of KATL runway 9L)\n",
    "IAF_9R = (33.63093611111111, -84.86295) # waypoint ANDIY (IAF of KATL runway 9R)\n",
    "IF_27R = (33.63430555555556, -84.12904722222221) # waypoint MAASN (IF of KATL runway 27R)\n",
    "IAF_27R = (33.633874999999996, -83.99111666666667) # waypoint YOUYU (IAF of KATL runway 27R)\n",
    "radius = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query based on Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+---+---+---+\n",
      "|recType|recTime|acId|lat|lon|alt|\n",
      "+-------+-------+----+---+---+---+\n",
      "+-------+-------+----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['recTime'] == timestamp).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of flight in the airspace at the given timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['recTime'] == timestamp).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight record of a given callsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['acId'] == 'UAL533').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['alt'] == 20.06).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight records of multiple given callsigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "df.where(f.col(\"acId\").isin({\"CLX56L\", \"DAL1323\"})).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectangular query at given location and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['recTime'] == timestamp).\\\n",
    "filter(df['lat']>IAF_9L[0]-radius).filter(df['lat']<IAF_9L[0]+radius).\\\n",
    "filter(df['lon']>IAF_9L[1]-radius).filter(df['lon']<IAF_9L[1]+radius).\\\n",
    "count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['lat']>=IAF_9R[0]-radius).filter(df['lat']<=IAF_9R[0]+radius).\\\n",
    "filter(df['lon']>=IAF_9R[1]-radius).filter(df['lon']<=IAF_9R[1]+radius).\\\n",
    "count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of flight callsigns in the rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"acId\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return callsigns within a radius in lat/lon degrees\n",
    "* GeoSpark needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Call Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list = [x['acId'] for x in df.select(\"acId\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate departure/arrival aircrafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dep = []\n",
    "cs_arr = []\n",
    "cs_unknown = []\n",
    "for x in df.select('acId').distinct().collect():\n",
    "    temp_df = df.filter(df['acId'] == x['acId'])\n",
    "    if temp_df.select(['alt']).take(1)[0][0] == 10.06:\n",
    "        cs_dep.append(x['acId'])\n",
    "    elif temp_df.orderBy(temp_df.recTime.desc()).select('alt').take(1)[0][0] == 10.06:\n",
    "        cs_arr.append(x['acId'])\n",
    "    else:\n",
    "        cs_unknown.append(x['acId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find landing points close to FAF_9R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arr = df.filter(df.acId.isin(cs_arr) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faf9rflight = df_arr.filter(df_arr['lat']>=FAF_9R[0]-radius).filter(df_arr['lat']<=FAF_9R[0]+radius).\\\n",
    "filter(df_arr['lon']>=FAF_9R[1]-radius).filter(df_arr['lon']<=FAF_9R[1]+radius)\n",
    "faf9rflight.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faf9rflight.coalesce(1).write.csv('./faf9rflights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['acId'] == 'NKS1561').show(2000)  # randomly pick one callsign from cs_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple arrival flights in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # number of flight to plot\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for cs in cs_arr:\n",
    "    df_arr = df.filter(df['acId'] == cs)\n",
    "    yy = np.array(df_arr.select(\"lat\").collect()).reshape(-1)\n",
    "    xx = np.array(df_arr.select(\"lon\").collect()).reshape(-1)\n",
    "    \n",
    "    plt.plot(xx, yy)\n",
    "    plt.xlabel('Longitude/Degrees')\n",
    "    plt.ylabel('Latitude/Degrees')\n",
    "    \n",
    "    i = i + 1\n",
    "    if i == n:\n",
    "        break\n",
    "\n",
    "plt.plot(IAF_9L[1], IAF_9L[0], label='IAF_9L', marker='*')     \n",
    "plt.plot(IAF_9R[1], IAF_9R[0], label='IAF_9R', marker='^')     \n",
    "plt.plot(IAF_27R[1], IAF_27R[0], label='IAF_27R', marker='D')     \n",
    "plt.plot(FAF_9L[1], FAF_9L[0], label='FAF_9L', marker='o')     \n",
    "plt.plot(IF_27R[1], IF_27R[0], label='IF_27R', marker='v')  \n",
    "plt.plot(FAF_9R[1], FAF_9R[0], label='FAF_9R', marker='X')     \n",
    "plt.plot(IF_9R[1], IF_9R[0], label='IF_9R', marker='P')     \n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('arrival_{}.png'.format(n), dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple departure flights in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # number of flight to plot\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for cs in cs_dep:\n",
    "    df_arr = df.filter(df['acId'] == cs)\n",
    "    yy = np.array(df_arr.select(\"lat\").collect()).reshape(-1)\n",
    "    xx = np.array(df_arr.select(\"lon\").collect()).reshape(-1)\n",
    "    \n",
    "    plt.plot(xx, yy)\n",
    "    plt.xlabel('Longitude/Degrees')\n",
    "    plt.ylabel('Latitude/Degrees')\n",
    "    \n",
    "    i = i + 1\n",
    "    if i == n:\n",
    "        break\n",
    "\n",
    "plt.plot(IAF_9L[1], IAF_9L[0], label='IAF_9L', marker='*')     \n",
    "plt.plot(IAF_9R[1], IAF_9R[0], label='IAF_9R', marker='^')     \n",
    "plt.plot(IAF_27R[1], IAF_27R[0], label='IAF_27R', marker='D')     \n",
    "plt.plot(FAF_9L[1], FAF_9L[0], label='FAF_9L', marker='o')     \n",
    "plt.plot(IF_27R[1], IF_27R[0], label='IF_27R', marker='v')  \n",
    "plt.plot(FAF_9R[1], FAF_9R[0], label='FAF_9R', marker='X')     \n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('departure_{}.png'.format(n), dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple unknown flights in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # number of flight to plot\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for cs in cs_unknown:\n",
    "    df_arr = df.filter(df['acId'] == cs)\n",
    "    yy = np.array(df_arr.select(\"lat\").collect()).reshape(-1)\n",
    "    xx = np.array(df_arr.select(\"lon\").collect()).reshape(-1)\n",
    "    \n",
    "    plt.plot(xx, yy)\n",
    "    plt.xlabel('Longitude/Degrees')\n",
    "    plt.ylabel('Latitude/Degrees')\n",
    "    \n",
    "    i = i + 1\n",
    "    if i == n:\n",
    "        break\n",
    "\n",
    "plt.plot(IAF_9L[1], IAF_9L[0], label='IAF_9L', marker='*')     \n",
    "plt.plot(IAF_9R[1], IAF_9R[0], label='IAF_9R', marker='^')     \n",
    "plt.plot(IAF_27R[1], IAF_27R[0], label='IAF_27R', marker='D')     \n",
    "plt.plot(FAF_9L[1], FAF_9L[0], label='FAF_9L', marker='o')     \n",
    "plt.plot(IF_27R[1], IF_27R[0], label='IF_27R', marker='v')\n",
    "plt.plot(FAF_9R[1], FAF_9R[0], label='FAF_9R', marker='X')     \n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('unknown_{}.png'.format(n), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return callsigns within a radius in km \n",
    "* Euclidean distance slow the calculation\n",
    "* GeoSpark can be used here to speed up the searching with buildin tree structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.select(\"*\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance function between two lat/lon\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def getDist(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "  R = 6373.0\n",
    "  lat1, lon1, lat2, lon2 = radians(lat1), radians(lon1), radians(lat2), radians(lon2)\n",
    "  dlon, dlat = lon2 - lon1, lat2 - lat1\n",
    "  a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "  c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "  return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply distance function to dataframe\n",
    "pandas_df['dist']=list(map(lambda k: getDist(pandas_df.loc[k]['lat'], pandas_df.loc[k]['lon'], IAF_9R[0], IAF_9R[1]), pandas_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getL2(lat1, lon1, lat2, lon2):\n",
    "    return sqrt((lat1 - lat2)**2 + (lon1 - lon2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "pandas_df['dist']=list(map(lambda k: getL2(pandas_df.loc[k]['lat'], pandas_df.loc[k]['lon'], FAF_9R[0], FAF_9R[1]), pandas_df.index))\n",
    "t1 = time.time()\n",
    "print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df[pandas_df['dist']<0.1]['acId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df[pandas_df['dist']<0.5]['acId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure GeoSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geospark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the packages locally\n",
    "<ul>\n",
    "<li>The source code for SNAPSHOT version is here: https://github.com/apache/incubator-sedona/releases</li>\n",
    "<li>Download or clone the source code, in the root folder, run: “mvn clean install -DskipTests\"</li>\n",
    "<li>Then copy the compiled jars in core/target and sql/target to SPARK_HOME/jars </li>\n",
    "</ul>\n",
    "\n",
    "check .travis.xml in the root directory of the source code for additional informations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geospark.register import upload_jars\n",
    "from geospark.register import GeoSparkRegistrator\n",
    "upload_jars()\n",
    "GeoSparkRegistrator.registerAll(spark)\n",
    "from pyspark import SparkConf\n",
    "from geospark.utils import GeoSparkKryoRegistrator, KryoSerializer\n",
    "SparkConf().set(\"spark.serializer\", KryoSerializer.getName)\n",
    "SparkConf().set(\"spark.kryo.registrator\", GeoSparkKryoRegistrator.getName)\n",
    "from geospark.utils.adapter import Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 3rd party jars\n",
    "spark.sparkContext.addPyFile(\"/home/ypang6/anaconda3/lib/python3.7/site-packages/pyspark/jars/geospark-sql_3.0-1.3.2-SNAPSHOT.jar\")\n",
    "spark.sparkContext.addPyFile(\"/home/ypang6/anaconda3/lib/python3.7/site-packages/pyspark/jars/geospark-1.3.2-SNAPSHOT.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine columns\n",
    "# from pyspark.sql import functions as f\n",
    "# df = df.withColumn('point', f.concat(f.col('lat'), f.lit(','), f.col('lon')))\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SpatialDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register pyspark df in SQL\n",
    "df.registerTempTable(\"pointtable\")\n",
    "\n",
    "# create shape column in geospark\n",
    "spatialdf = spark.sql(\n",
    "  \"\"\"\n",
    "  SELECT ST_Point(CAST(lat AS Decimal(24, 20)), CAST(lon AS Decimal(24, 20))) AS geom, recTime, acId, alt\n",
    "  FROM pointtable\n",
    "  \"\"\")\n",
    "\n",
    "spatialdf.createOrReplaceTempView(\"spatialdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geom: geometry (nullable = false)\n",
      " |-- recTime: integer (nullable = true)\n",
      " |-- acId: string (nullable = true)\n",
      " |-- alt: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spatialdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----+-----+\n",
      "|                geom|   recTime|acId|  alt|\n",
      "+--------------------+----------+----+-----+\n",
      "|POINT (33.62935 -...|1564632506|OPS7|10.06|\n",
      "|POINT (33.62948 -...|1564632507|OPS7|10.06|\n",
      "|POINT (33.62951 -...|1564632508|OPS7|10.06|\n",
      "|POINT (33.62955 -...|1564632509|OPS7|10.06|\n",
      "|POINT (33.62955 -...|1564632510|OPS7|10.06|\n",
      "+--------------------+----------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spatialdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert SpatialDF to SpatialRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_rdd = Adapter.toSpatialRdd(spatialdf, \"geom\")\n",
    "spatial_rdd.analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial KNN Query with SQL APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register pyspark df in SQL\n",
    "spatialdf.registerTempTable(\"spatialdf\")\n",
    "\n",
    "SQL_spatial_knn_query_result = spark.sql(\n",
    "  \"\"\"\n",
    "  SELECT ST_Distance(ST_Point(33.631727, -84.549405), geom) AS Dist, recTime, acId, alt\n",
    "  FROM spatialdf\n",
    "  ORDER BY Dist ASC\n",
    "  LIMIT 100\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_spatial_knn_query_result.createOrReplaceTempView(\"query1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-----+\n",
      "|                Dist|   recTime|   acId|  alt|\n",
      "+--------------------+----------+-------+-----+\n",
      "|6.777905281830643E-5|1564708076|DAL2105|27.13|\n",
      "|9.441398201858383E-5|1564706454|DAL2035|26.69|\n",
      "|1.087841900174624...|1564707735|DAL1402|25.81|\n",
      "|1.134636505735247...|1564721025|AAL2043|26.88|\n",
      "|1.194738465072900...|1564708957|RPA4525|26.69|\n",
      "|1.303610371190070...|1564708352|DAL1680|26.56|\n",
      "|1.468128059700728...|1564709152|SWA1396|26.56|\n",
      "|1.522957648883272...|1564707029|DAL2826| 25.5|\n",
      "|1.524270317115531...|1564707240|DAL1705|26.75|\n",
      "|1.641767340291201...|1564707834| DAL362|26.63|\n",
      "|1.820823989245820...|1564714187|NKS1821|26.75|\n",
      "|1.968603565886242...|1564707503| NKS221|26.25|\n",
      "|2.061892334777792...|1564706630|DAL1778| 26.5|\n",
      "|2.107937380432419...|1564713509|EDV5418|26.75|\n",
      "|2.342520010690241...|1564712954|DAL2495|26.88|\n",
      "|2.353592997986974...|1564713631|SWA1677|26.19|\n",
      "|2.503477581179296E-4|1564707962|EDV3323|25.75|\n",
      "|2.592951985760132...|1564709674|DAL2875|26.75|\n",
      "|2.983186216079487E-4|1564706909|DAL1250|25.94|\n",
      "|3.201156041184424...|1564706532|EDV5337|26.69|\n",
      "+--------------------+----------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL_spatial_knn_query_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial KNN Query with Python APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f732342fc50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set extra class path\n",
    "SPARK_GeoSpark_SQL = \"/home/ypang6/anaconda3/lib/python3.7/site-packages/pyspark/jars/geospark-sql_3.0-1.3.2-SNAPSHOT.jar\"\n",
    "SPARK_GeoSpark = '/home/ypang6/anaconda3/lib/python3.7/site-packages/pyspark/jars/geospark-1.3.2-SNAPSHOT.jar'\n",
    "SparkConf().set(\"spark.driver.extraClassPath\", SPARK_GeoSpark)\n",
    "SparkConf().set(\"spark.executor.extraClassPath\", SPARK_GeoSpark)\n",
    "SparkConf().set(\"spark.driver.extraClassPath\", SPARK_GeoSpark_SQL)\n",
    "SparkConf().set(\"spark.executor.extraClassPath\", SPARK_GeoSpark_SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'JavaPackage' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-56db1f589101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0musing_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNQuery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialKnnQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_rdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geospark/utils/decorators.py\u001b[0m in \u001b[0;36mrun_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst_not_fulfill_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 raise ModuleNotFoundError(f\"Did not found {has_all_libs[first_not_fulfill_value]}, make sure that was correctly imported via py4j\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geospark/core/spatialOperator/knn_query.py\u001b[0m in \u001b[0;36mSpatialKnnQuery\u001b[0;34m(self, spatialRDD, originalQueryPoint, k, useIndex)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \"\"\"\n\u001b[1;32m     25\u001b[0m         \u001b[0mjvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatialRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mjvm_geom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeometryAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_jvm_geometry_from_base_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginalQueryPoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mknn_neighbours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNNQuery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialKnnQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatialRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_srdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_geom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geospark/utils/geometry_adapter.py\u001b[0m in \u001b[0;36mcreate_jvm_geometry_from_base_geometry\u001b[0;34m(cls, jvm, geom)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mdecoded_geom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeometryFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mjvm_geom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeometryAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserializeToGeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_geom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjvm_geom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
     ]
    }
   ],
   "source": [
    "from geospark.core.spatialOperator import KNNQuery\n",
    "from geospark.core.enums import IndexType\n",
    "from shapely.geometry import Point\n",
    "\n",
    "loc = (33.631727, -84.549405)\n",
    "\n",
    "point = Point(loc[0], loc[1])\n",
    "\n",
    "k = 5 ## K Nearest Neighbors\n",
    "\n",
    "build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query\n",
    "spatial_rdd.buildIndex(IndexType.RTREE, build_on_spatial_partitioned_rdd)\n",
    "\n",
    "using_index = True\n",
    "result = KNNQuery.SpatialKnnQuery(spatial_rdd, point, k, using_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??KNNQuery.SpatialKnnQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Range Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geospark.core.geom.envelope import Envelope\n",
    "from geospark.core.enums import IndexType\n",
    "from geospark.core.spatialOperator import RangeQuery\n",
    "\n",
    "range_query_window = Envelope(-90.01, -80.01, 30.01, 40.01)\n",
    "consider_boundary_intersection = False ## Only return gemeotries fully covered by the window\n",
    "\n",
    "build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query\n",
    "spatial_rdd.buildIndex(IndexType.QUADTREE, build_on_spatial_partitioned_rdd)\n",
    "\n",
    "using_index = True\n",
    "\n",
    "query_result = RangeQuery.SpatialRangeQuery(\n",
    "    spatial_rdd,\n",
    "    range_query_window,\n",
    "    consider_boundary_intersection,\n",
    "    using_index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Radius Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geospark.core.SpatialRDD import CircleRDD\n",
    "from geospark.core.enums import GridType\n",
    "from geospark.core.spatialOperator import JoinQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from pyspark.sql.types import IntegerType, StructField, StructType\n",
    "from geospark.sql.types import GeometryType\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"recTime\", IntegerType(), False),\n",
    "        StructField(\"geom\", GeometryType(), False)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "timestamp = 1567346400\n",
    "loc = (33.631727, -84.549405)\n",
    "\n",
    "point = Point(loc[0], loc[1])\n",
    "\n",
    "data = [\n",
    "    [timestamp, point]\n",
    "]\n",
    "\n",
    "\n",
    "object_df = spark.createDataFrame(data, schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_rdd = Adapter.toSpatialRdd(object_df, \"geom\")\n",
    "object_rdd.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_rdd = CircleRDD(object_rdd, 0.1) ## Create a CircleRDD using the given distance\n",
    "circle_rdd.analyze()\n",
    "\n",
    "circle_rdd.spatialPartitioning(GridType.KDBTREE)\n",
    "spatial_rdd.spatialPartitioning(circle_rdd.getPartitioner())\n",
    "\n",
    "consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD\n",
    "using_index = False\n",
    "\n",
    "result = JoinQuery.DistanceJoinQueryFlat(spatial_rdd, circle_rdd, using_index, consider_boundary_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create shape column in geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas\n",
    "# gdf = geopandas.GeoDataFrame(\n",
    "#     df, geometry=geopandas.points_from_xy(df.Longitude, df.Latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
