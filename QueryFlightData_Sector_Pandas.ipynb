{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data with Pandas\n",
    "* Reference to paraatm@https://github.com/ymlasu/para-atm/tree/master/paraatm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg_resources.extern import packaging\n",
    "\n",
    "def parse_version(v):\n",
    "    try:\n",
    "        return packaging.version.Version(v)\n",
    "    except packaging.version.InvalidVersion:\n",
    "        return packaging.version.LegacyVersion(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iff_file(filename, record_types=3, callsigns=None, chunksize=50000, encoding='latin-1'):\n",
    "    \"\"\"\n",
    "    Read IFF file and return data frames for requested record types\n",
    "    \n",
    "    From IFF 2.15 specification, record types include:\n",
    "    2. header\n",
    "    3. track point\n",
    "    4. flight plan\n",
    "    5. data source program\n",
    "    6. sectorization\n",
    "    7. minimum safe altitude\n",
    "    8. flight progress\n",
    "    9. aircraft state\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        File to read\n",
    "    record_types : int, sequence of ints, or 'all'\n",
    "        Record types to return\n",
    "    callsigns : None, string, or list of strings\n",
    "        If None, return records for all aircraft callsigns.\n",
    "        Otherwise, only return records that match the given callsign\n",
    "        (in the case of a single string) or match one of the specified\n",
    "        callsigns (in the case of a list of strings).\n",
    "    chunksize: int\n",
    "        Number of rows that are read at a time by pd.read_csv.  This\n",
    "        limits memory usage when working with large files, as we can\n",
    "        extract out the desired rows from each chunk, intead of\n",
    "        reading everything into one large DataFrame and then taking a\n",
    "        subset.\n",
    "    encoding: str\n",
    "        Encoding argument passed on to open and pd.read_csv.  Using\n",
    "        'latin-1' instead of the default will suppress errors that\n",
    "        might otherwise occur with minor data corruption.  See\n",
    "        http://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame or dict of DataFrames\n",
    "       If record_types is a scalar, return a DataFrame containing the\n",
    "       data for that record type only.  Otherwise, return a dictionary\n",
    "       mapping each requested record type to a corresponding DataFrame.\n",
    "    \"\"\"\n",
    "    # Note default record_type of 3 (track point) is used for\n",
    "    # consistency with the behavior of other functions that expect\n",
    "    # flight tracking data\n",
    "\n",
    "    # Determine file format version.  This is in record type 1, which\n",
    "    # for now we assume to occur on the first line.\n",
    "    with open(filename, 'r') as f:\n",
    "        version = parse_version(f.readline().split(',')[2])\n",
    "\n",
    "    # Columns for each record type, from version 2.6 specification.\n",
    "    cols = {0:['recType','comment'],\n",
    "            1:['recType','fileType','fileFormatVersion'],\n",
    "            2:['recType','recTime','fltKey','bcnCode','cid','Source','msgType','AcId','recTypeCat','acType','Orig','Dest','opsType','estOrig','estDest'],\n",
    "            3:['recType','recTime','fltKey','bcnCode','cid','Source','msgType','AcId','recTypeCat','coord1','coord2','alt','significance','coord1Accur','coord2Accur','altAccur','groundSpeed','course','rateOfClimb','altQualifier','altIndicator','trackPtStatus','leaderDir','scratchPad','msawInhibitInd','assignedAltString','controllingFac','controllingSeg','receivingFac','receivingSec','activeContr','primaryContr','kybrdSubset','kybrdSymbol','adsCode','opsType','airportCode'],\n",
    "            4:['recType','recTime','fltKey','bcnCode','cid','Source','msgType','AcId','recTypeCat','acType','Orig','Dest','altcode','alt','maxAlt','assignedAltString','requestedAltString','route','estTime','fltCat','perfCat','opsType','equipList','coordinationTime','coordinationTimeType','leaderDir','scratchPad1','scratchPad2','fixPairScratchPad','prefDepArrRoute','prefDepRoute','prefArrRoute'],\n",
    "            5:['recType','dataSource','programName','programVersion'],\n",
    "            6:['recType','recTime','Source','msgType','rectypeCat','sectorizationString'],\n",
    "            7:['recType','recTime','fltKey','bcnCode','cid','Source','msgType','AcId','recTypeCat','coord1','coord2','alt','significance','coord1Accur','coord2Accur','altAccur','msawtype','msawTimeCat','msawLocCat','msawMinSafeAlt','msawIndex1','msawIndex2','msawVolID'],\n",
    "            8:['recType','recTime','fltKey','bcnCode','cid','Source','msgType','AcId','recTypeCat','acType','Orig','Dest','depTime','depTimeType','arrTime','arrTimeType'],\n",
    "            9:['recType','recTime','fltKey','bcnCode','cid','Source','msgType','AcId','recTypeCat','coord1','coord2','alt','pitchAngle','trueHeading','rollAngle','trueAirSpeed','fltPhaseIndicator'],\n",
    "            10:['recType','recTime','fltKey','bcnCode','cid','Source','msgType','AcId','recTypeCat','configType','configSpec']}\n",
    "\n",
    "    # For newer versions, additional columns are supported.  However,\n",
    "    # this code could be commented out, and it should still be\n",
    "    # compatible with newer versions, but just ignoring the additional\n",
    "    # columns.\n",
    "    if version >= parse_version('2.13'):\n",
    "        cols[2] += ['modeSCode']\n",
    "        cols[3] += ['trackNumber','tptReturnType','modeSCode']\n",
    "        cols[4] += ['coordinationPoint','coordinationPointType','trackNumber','modeSCode']\n",
    "    if version >= parse_version('2.15'):\n",
    "        cols[3] += ['sensorTrackNumberList','spi','dvs','dupM3a','tid']\n",
    "\n",
    "    # Determine the record type of each row\n",
    "    with open(filename, 'r', encoding=encoding) as f:\n",
    "        # An alternative, using less memory, would be to directly\n",
    "        # create skiprows indices for a particular record type, using\n",
    "        # a comprehension on enumerate(f); however, that would not\n",
    "        # allow handling multiple record types.\n",
    "        line_record_types = [int(line.split(',')[0]) for line in f]\n",
    "\n",
    "    # Determine which record types to retrieve, and whether the result\n",
    "    # should be a scalar or dict:\n",
    "    if record_types == 'all':\n",
    "        record_types = np.unique(line_record_types)\n",
    "        scalar_result = False\n",
    "    elif hasattr(record_types, '__getitem__'):\n",
    "        scalar_result = False\n",
    "    else:\n",
    "        record_types = [record_types]\n",
    "        scalar_result = True\n",
    "\n",
    "    if callsigns is not None:\n",
    "        callsigns = list(np.atleast_1d(callsigns))\n",
    "\n",
    "\n",
    "    data_frames = dict()\n",
    "    for record_type in record_types:\n",
    "        # Construct list of rows to skip:\n",
    "        skiprows = [i for i,lr in enumerate(line_record_types) if lr != record_type]\n",
    "        \n",
    "        # Passing usecols is necessary because for some records, the\n",
    "        # actual data has extraneous empty columns at the end, in which\n",
    "        # case the data does not seem to get read correctly without\n",
    "        # usecols\n",
    "        if callsigns is None:\n",
    "            df = pd.concat((chunk for chunk in pd.read_csv(filename, header=None, skiprows=skiprows, names=cols[record_type], usecols=cols[record_type], na_values='?', encoding=encoding, chunksize=chunksize, low_memory=False)), ignore_index=True)\n",
    "        else:\n",
    "            df = pd.concat((chunk[chunk['AcId'].isin(callsigns)] for chunk in pd.read_csv(filename, header=None, skiprows=skiprows, names=cols[record_type], usecols=cols[record_type], na_values='?', encoding=encoding, chunksize=chunksize, low_memory=False)), ignore_index=True)\n",
    "\n",
    "        # For consistency with other PARA-ATM data:\n",
    "        df.rename(columns={'recTime':'time',\n",
    "                           'AcId':'callsign',\n",
    "                           'coord1':'latitude',\n",
    "                           'coord2':'longitude',\n",
    "                           'alt':'altitude',\n",
    "                           'rateOfClimb':'rocd',\n",
    "                           'groundSpeed':'tas',\n",
    "                           'course':'heading'},\n",
    "                  inplace=True)\n",
    "\n",
    "        if 'time' in df:\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "        if 'altitude' in df:\n",
    "            df['altitude'] *= 100 # Convert 100s ft to ft\n",
    "\n",
    "        # Store to dict of data frames\n",
    "        data_frames[record_type] = df\n",
    "\n",
    "    if scalar_result:\n",
    "        result = data_frames[record_types[0]]\n",
    "    else:\n",
    "        result = data_frames\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Date for Sector IFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 20190801\n",
    "import glob\n",
    "file_path = glob.glob(\"/media/ypang6/paralab/Research/data/ZTL/IFF_ZTL_{}*.csv\".format(date))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = read_iff_file(file_path, record_types=2, chunksize = 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recType</th>\n",
       "      <th>time</th>\n",
       "      <th>fltKey</th>\n",
       "      <th>bcnCode</th>\n",
       "      <th>cid</th>\n",
       "      <th>Source</th>\n",
       "      <th>msgType</th>\n",
       "      <th>callsign</th>\n",
       "      <th>recTypeCat</th>\n",
       "      <th>acType</th>\n",
       "      <th>Orig</th>\n",
       "      <th>Dest</th>\n",
       "      <th>opsType</th>\n",
       "      <th>estOrig</th>\n",
       "      <th>estDest</th>\n",
       "      <th>modeSCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-01 04:49:48.000000000</td>\n",
       "      <td>187079</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>728</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SKQ74</td>\n",
       "      <td>1</td>\n",
       "      <td>PC12</td>\n",
       "      <td>KBUY</td>\n",
       "      <td>KIAD</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-01 04:09:03.000000000</td>\n",
       "      <td>187080</td>\n",
       "      <td>7134.0</td>\n",
       "      <td>885</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAL2681</td>\n",
       "      <td>1</td>\n",
       "      <td>A321</td>\n",
       "      <td>KATL</td>\n",
       "      <td>KRDU</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A45F64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-01 04:02:38.000000000</td>\n",
       "      <td>187081</td>\n",
       "      <td>7457.0</td>\n",
       "      <td>928</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LN441PC</td>\n",
       "      <td>1</td>\n",
       "      <td>LJ35</td>\n",
       "      <td>OTK337060</td>\n",
       "      <td>KGBG</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-01 04:00:19.000000000</td>\n",
       "      <td>187082</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>537</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAL2690</td>\n",
       "      <td>1</td>\n",
       "      <td>B752</td>\n",
       "      <td>37.016667/-80.383333</td>\n",
       "      <td>KATL</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>A8E20F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-01 04:06:26.000000000</td>\n",
       "      <td>187083</td>\n",
       "      <td>7471.0</td>\n",
       "      <td>423</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UPS9603</td>\n",
       "      <td>1</td>\n",
       "      <td>B752</td>\n",
       "      <td>ATL130032</td>\n",
       "      <td>KSDF</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A5ADFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-02 04:27:06.751000166</td>\n",
       "      <td>204747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>981</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JIA9935</td>\n",
       "      <td>1</td>\n",
       "      <td>CRJ7</td>\n",
       "      <td>KGSO</td>\n",
       "      <td>KCAK</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A657AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-02 03:23:39.922999859</td>\n",
       "      <td>204933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SKQ43</td>\n",
       "      <td>1</td>\n",
       "      <td>PC12</td>\n",
       "      <td>KBHM</td>\n",
       "      <td>KMLU</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-02 04:55:49.751000166</td>\n",
       "      <td>204975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JIA5696</td>\n",
       "      <td>1</td>\n",
       "      <td>CRJ9</td>\n",
       "      <td>KCLT</td>\n",
       "      <td>KVPS</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A6F326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-02 04:56:27.434999943</td>\n",
       "      <td>204976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAL2577</td>\n",
       "      <td>1</td>\n",
       "      <td>B738</td>\n",
       "      <td>KCLT</td>\n",
       "      <td>KMIA</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-02 04:57:41.230999947</td>\n",
       "      <td>204977</td>\n",
       "      <td>6763.0</td>\n",
       "      <td>094</td>\n",
       "      <td>0/ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UAL1772</td>\n",
       "      <td>1</td>\n",
       "      <td>A319</td>\n",
       "      <td>VXV310047</td>\n",
       "      <td>KRDU</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AB050F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9752 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recType                          time  fltKey  bcnCode  cid Source  \\\n",
       "0           2 2019-08-01 04:49:48.000000000  187079   2510.0  728  0/ZTL   \n",
       "1           2 2019-08-01 04:09:03.000000000  187080   7134.0  885  0/ZTL   \n",
       "2           2 2019-08-01 04:02:38.000000000  187081   7457.0  928  0/ZTL   \n",
       "3           2 2019-08-01 04:00:19.000000000  187082   2627.0  537  0/ZTL   \n",
       "4           2 2019-08-01 04:06:26.000000000  187083   7471.0  423  0/ZTL   \n",
       "...       ...                           ...     ...      ...  ...    ...   \n",
       "9747        2 2019-08-02 04:27:06.751000166  204747      NaN  981  0/ZTL   \n",
       "9748        2 2019-08-02 03:23:39.922999859  204933      NaN  372  0/ZTL   \n",
       "9749        2 2019-08-02 04:55:49.751000166  204975      NaN  406  0/ZTL   \n",
       "9750        2 2019-08-02 04:56:27.434999943  204976      NaN  333  0/ZTL   \n",
       "9751        2 2019-08-02 04:57:41.230999947  204977   6763.0  094  0/ZTL   \n",
       "\n",
       "      msgType callsign  recTypeCat acType                  Orig  Dest opsType  \\\n",
       "0         NaN    SKQ74           1   PC12                  KBUY  KIAD       O   \n",
       "1         NaN  DAL2681           1   A321                  KATL  KRDU       D   \n",
       "2         NaN  LN441PC           1   LJ35             OTK337060  KGBG       O   \n",
       "3         NaN  DAL2690           1   B752  37.016667/-80.383333  KATL       A   \n",
       "4         NaN  UPS9603           1   B752             ATL130032  KSDF       O   \n",
       "...       ...      ...         ...    ...                   ...   ...     ...   \n",
       "9747      NaN  JIA9935           1   CRJ7                  KGSO  KCAK       D   \n",
       "9748      NaN    SKQ43           1   PC12                  KBHM  KMLU       D   \n",
       "9749      NaN  JIA5696           1   CRJ9                  KCLT  KVPS       D   \n",
       "9750      NaN  AAL2577           1   B738                  KCLT  KMIA       D   \n",
       "9751      NaN  UAL1772           1   A319             VXV310047  KRDU       O   \n",
       "\n",
       "     estOrig estDest modeSCode  \n",
       "0        NaN     NaN       NaN  \n",
       "1        NaN     NaN    A45F64  \n",
       "2        NaN     NaN       NaN  \n",
       "3        NaN     ATL    A8E20F  \n",
       "4        NaN     NaN    A5ADFE  \n",
       "...      ...     ...       ...  \n",
       "9747     NaN     NaN    A657AD  \n",
       "9748     NaN     NaN       NaN  \n",
       "9749     NaN     NaN    A6F326  \n",
       "9750     NaN     NaN       NaN  \n",
       "9751     NaN     NaN    AB050F  \n",
       "\n",
       "[9752 rows x 16 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Pandas into PySpark df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Terminal_Area_Flight_Data_Query\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd_df.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+-------+---+------+-------+--------+----------+------+--------------------+----+-------+-------+-------+---------+\n",
      "|recType|                time|fltKey|bcnCode|cid|Source|msgType|callsign|recTypeCat|acType|                Orig|Dest|opsType|estOrig|estDest|modeSCode|\n",
      "+-------+--------------------+------+-------+---+------+-------+--------+----------+------+--------------------+----+-------+-------+-------+---------+\n",
      "|      2|2019-08-01 04:49:...|187079| 2510.0|728| 0/ZTL|    nan|   SKQ74|         1|  PC12|                KBUY|KIAD|      O|    nan|    nan|      nan|\n",
      "|      2|2019-08-01 04:09:...|187080| 7134.0|885| 0/ZTL|    nan| DAL2681|         1|  A321|                KATL|KRDU|      D|    nan|    nan|   A45F64|\n",
      "|      2|2019-08-01 04:02:...|187081| 7457.0|928| 0/ZTL|    nan| LN441PC|         1|  LJ35|           OTK337060|KGBG|      O|    nan|    nan|      nan|\n",
      "|      2|2019-08-01 04:00:...|187082| 2627.0|537| 0/ZTL|    nan| DAL2690|         1|  B752|37.016667/-80.383333|KATL|      A|    nan|    ATL|   A8E20F|\n",
      "|      2|2019-08-01 04:06:...|187083| 7471.0|423| 0/ZTL|    nan| UPS9603|         1|  B752|           ATL130032|KSDF|      O|    nan|    nan|   A5ADFE|\n",
      "+-------+--------------------+------+-------+---+------+-------+--------+----------+------+--------------------+----+-------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- recType: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- fltKey: string (nullable = true)\n",
      " |-- bcnCode: string (nullable = true)\n",
      " |-- cid: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- msgType: string (nullable = true)\n",
      " |-- callsign: string (nullable = true)\n",
      " |-- recTypeCat: string (nullable = true)\n",
      " |-- acType: string (nullable = true)\n",
      " |-- Orig: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- opsType: string (nullable = true)\n",
      " |-- estOrig: string (nullable = true)\n",
      " |-- estDest: string (nullable = true)\n",
      " |-- modeSCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
