{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set spark environments\n",
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = '/home/ypang6/spark-2.4.7-bin-hadoop2.7'\n",
    "os.environ[\"PYTHONPATH\"] = '/home/ypang6/anaconda3/bin/python3.7'\n",
    "os.environ['PYSPARK_PYTHON'] = '/home/ypang6/anaconda3/bin/python3.7'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/home/ypang6/anaconda3/bin/python3.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, ShortType, StringType, LongType, IntegerType, DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "from geospark.register import GeoSparkRegistrator\n",
    "from geospark.utils import GeoSparkKryoRegistrator, KryoSerializer\n",
    "from geospark.register import upload_jars\n",
    "from geospark.core.geom.envelope import Envelope\n",
    "from geospark.core.enums import IndexType\n",
    "from geospark.core.spatialOperator import RangeQuery\n",
    "from geospark.utils.adapter import Adapter\n",
    "upload_jars()\n",
    "spark = SparkSession.builder. \\\n",
    "    master(\"local[*]\"). \\\n",
    "    appName(\"TestApp\"). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", GeoSparkKryoRegistrator.getName). \\\n",
    "    getOrCreate()\n",
    "GeoSparkRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myschema = StructType([\n",
    "    StructField(\"recType\", ShortType(), True),  #1  //track point record type number\n",
    "    StructField(\"recTime\", StringType(), True),  #2  //seconds since midnigght 1/1/70 UTC\n",
    "    StructField(\"fltKey\", LongType(), True),  #3  //flight key\n",
    "    StructField(\"bcnCode\", IntegerType(), True),  #4  //digit range from 0 to 7\n",
    "    StructField(\"cid\", IntegerType(), True),  #5  //computer flight id\n",
    "    StructField(\"Source\", StringType(), True),  #6  //source of the record\n",
    "    StructField(\"msgType\", StringType(), True),  #7\n",
    "    StructField(\"acId\", StringType(), True),  #8  //call sign\n",
    "    StructField(\"recTypeCat\", StringType(), True),  #9\n",
    "    StructField(\"lat\", DoubleType(), True),  #10\n",
    "    StructField(\"lon\", DoubleType(), True),  #11\n",
    "    StructField(\"alt\", DoubleType(), True),  #12  //in 100s of feet\n",
    "    StructField(\"significance\", ShortType(), True),  #13 //digit range from 1 to 10\n",
    "    StructField(\"latAcc\", DoubleType(), True),  #14\n",
    "    StructField(\"lonAcc\", DoubleType(), True),  #15\n",
    "    StructField(\"altAcc\", DoubleType(), True),  #16\n",
    "    StructField(\"groundSpeed\", IntegerType(), True),  #17 //in knots\n",
    "    StructField(\"course\", DoubleType(), True),  #18  //in degrees from true north\n",
    "    StructField(\"rateOfClimb\", DoubleType(), True),  #19  //in feet per minute\n",
    "    StructField(\"altQualifier\", StringType(), True),  #20  //Altitude qualifier (the “B4 character”)\n",
    "    StructField(\"altIndicator\", StringType(), True),  #21  //Altitude indicator (the “C4 character”)\n",
    "    StructField(\"trackPtStatus\", StringType(), True),  #22  //Track point status (e.g., ‘C’ for coast)\n",
    "    StructField(\"leaderDir\", IntegerType(), True),  #23  //int 0-8 representing the direction of the leader line\n",
    "    StructField(\"scratchPad\", StringType(), True),  #24\n",
    "    StructField(\"msawInhibitInd\", ShortType(), True),  #25 // MSAW Inhibit Indicator (0=not inhibited, 1=inhibited)\n",
    "    StructField(\"assignedAltString\", StringType(), True),  #26\n",
    "    StructField(\"controllingFac\", StringType(), True),  #27\n",
    "    StructField(\"controllingSec\", StringType(), True),  #28\n",
    "    StructField(\"receivingFac\", StringType(), True),  #29\n",
    "    StructField(\"receivingSec\", StringType(), True),  #30\n",
    "    StructField(\"activeContr\", IntegerType(), True),  #31  // the active control number\n",
    "    StructField(\"primaryContr\", IntegerType(), True),  #32  //The primary(previous, controlling, or possible next)controller number\n",
    "    StructField(\"kybrdSubset\", StringType(), True),  #33  //identifies a subset of controller keyboards\n",
    "    StructField(\"kybrdSymbol\", StringType(), True),  #34  //identifies a keyboard within the keyboard subsets\n",
    "    StructField(\"adsCode\", IntegerType(), True),  #35  //arrival departure status code\n",
    "    StructField(\"opsType\", StringType(), True),  #36  //Operations type (O/E/A/D/I/U)from ARTS and ARTS 3A data\n",
    "    StructField(\"airportCode\", StringType(), True),  #37\n",
    "    StructField(\"trackNumber\", IntegerType(), True),  #38\n",
    "    StructField(\"tptReturnType\", StringType(), True),  #39\n",
    "    StructField(\"modeSCode\", StringType(), True),  #40\n",
    "    StructField(\"sensorTrackNumberList\", StringType(), True), #41 //a list of sensor/track number combinations\n",
    "    StructField(\"spi\", StringType(), True),  #42 // representing the Ident feature\n",
    "    StructField(\"dvs\", StringType(), True), #43 // indicate the aircraft is within a suppresion volumn area\n",
    "    StructField(\"dupM3a\", StringType(), True),  #44 // indicate 2 aircraft have the same mode 3a code\n",
    "    StructField(\"tid\", StringType(), True),  #45 //Aircraft Ident entered by pilot\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "date=20190801\n",
    "iff_file_path = glob.glob(\"/media/ypang6/paralab/Research/data/ZTL/IFF_ZTL_{}*.csv\".format(date))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iff sector data\n",
    "df = spark.read.csv(iff_file_path, header=False, sep=\",\", schema=myschema)\n",
    "\n",
    "# select columns\n",
    "cols = ['recType', 'recTime', 'acId', 'lat', 'lon', 'alt']\n",
    "df = df.select(*cols).filter(df['recType'] == 3).withColumn(\"recTime\", df['recTime'].cast(IntegerType()))\n",
    "\n",
    "# register pyspark df in SQL\n",
    "df.registerTempTable(\"pointtable\")\n",
    "\n",
    "# create shape column in geospark\n",
    "spatialdf = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT ST_Point(CAST(lat AS Decimal(24, 20)), CAST(lon AS Decimal(24, 20))) AS geom, recTime, acId\n",
    "    FROM pointtable\n",
    "    \"\"\")\n",
    "\n",
    "spatialdf.createOrReplaceTempView(\"spatialdf\")\n",
    "\n",
    "# register pyspark spatialdf in SQL\n",
    "spatialdf.registerTempTable(\"spatialdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984654"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+--------+---------+----+\n",
      "|recType|recTime   |acId |lat     |lon      |alt |\n",
      "+-------+----------+-----+--------+---------+----+\n",
      "|3      |1564634988|SKQ74|36.10444|-79.43917|23.0|\n",
      "|3      |1564634999|SKQ74|36.11417|-79.43611|26.0|\n",
      "|3      |1564635012|SKQ74|36.12389|-79.4325 |29.0|\n",
      "|3      |1564635024|SKQ74|36.13333|-79.42889|32.0|\n",
      "|3      |1564635036|SKQ74|36.14278|-79.42583|37.0|\n",
      "|3      |1564635048|SKQ74|36.1525 |-79.42278|40.0|\n",
      "|3      |1564635059|SKQ74|36.16083|-79.42   |43.0|\n",
      "|3      |1564635072|SKQ74|36.17139|-79.41667|46.0|\n",
      "|3      |1564635084|SKQ74|36.18056|-79.41389|48.0|\n",
      "|3      |1564635096|SKQ74|36.19028|-79.41056|51.0|\n",
      "|3      |1564635108|SKQ74|36.2    |-79.40722|54.0|\n",
      "|3      |1564635120|SKQ74|36.21   |-79.40389|58.0|\n",
      "|3      |1564635132|SKQ74|36.21944|-79.40056|60.0|\n",
      "|3      |1564635143|SKQ74|36.22833|-79.39778|63.0|\n",
      "|3      |1564635155|SKQ74|36.23833|-79.39444|66.0|\n",
      "|3      |1564635167|SKQ74|36.24806|-79.39083|69.0|\n",
      "|3      |1564635180|SKQ74|36.25806|-79.38778|72.0|\n",
      "|3      |1564635191|SKQ74|36.26778|-79.38444|75.0|\n",
      "|3      |1564635204|SKQ74|36.2775 |-79.38111|77.0|\n",
      "|3      |1564635216|SKQ74|36.2875 |-79.3775 |80.0|\n",
      "+-------+----------+-----+--------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_range_query_result = spark.sql(\n",
    "  \"\"\"\n",
    "    SELECT *\n",
    "    FROM spatialdf\n",
    "    WHERE ST_Contains(ST_PolygonFromEnvelope(33.62, 33.64, -84.54, -84.56), geom)\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----------+-------+\n",
      "|geom                      |recTime   |acId   |\n",
      "+--------------------------+----------+-------+\n",
      "|POINT (29.7275 -82.54639) |1564632158|LN441PC|\n",
      "|POINT (29.74972 -82.56111)|1564632170|LN441PC|\n",
      "|POINT (29.7725 -82.57694) |1564632182|LN441PC|\n",
      "|POINT (29.79444 -82.59222)|1564632194|LN441PC|\n",
      "|POINT (29.81667 -82.60694)|1564632206|LN441PC|\n",
      "|POINT (29.83944 -82.62167)|1564632218|LN441PC|\n",
      "|POINT (29.86167 -82.63611)|1564632230|LN441PC|\n",
      "|POINT (29.885 -82.65083)  |1564632242|LN441PC|\n",
      "|POINT (29.90778 -82.66472)|1564632254|LN441PC|\n",
      "|POINT (29.93111 -82.67889)|1564632266|LN441PC|\n",
      "+--------------------------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL_range_query_result.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_radius_query_result = spark.sql(\n",
    "  \"\"\"\n",
    "  SELECT *\n",
    "  FROM spatialdf\n",
    "  WHERE ST_Distance(ST_Point(33.63172, -84.54941), geom) < 0.01\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_radius_query_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_rdd = Adapter.toSpatialRdd(spatialdf, \"geom\")\n",
    "range_query_window = Envelope(-84.56, -84.54, 33.62, 33.64)\n",
    "\n",
    "consider_boundary_intersection = False ## Only return gemeotries fully covered by the window\n",
    "build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query\n",
    "spatial_rdd.buildIndex(IndexType.QUADTREE, build_on_spatial_partitioned_rdd)\n",
    "\n",
    "using_index = True\n",
    "\n",
    "query_result = RangeQuery.SpatialRangeQuery(\n",
    "    spatial_rdd,\n",
    "    range_query_window,\n",
    "    consider_boundary_intersection,\n",
    "    using_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result.map(lambda x: x.geom.length).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
